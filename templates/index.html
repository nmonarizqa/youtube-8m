<html>
<head>
  <title>Beauty Guru Recommender</title>
  <link href="{{ url_for('static', filename='css/bootstrap.min.css') }}" rel="stylesheet">
  <link href="{{ url_for('static', filename='css/custom.css') }}" rel="stylesheet">
  <script src="{{ url_for('static', filename='js/bootstrap.min.js') }}"></script>
</head>
<body>
  <div class="container" id="explanation" style="margin: 40px;">
    <div class="row">
      <div class="col-sm-6 col-sm-offset-3">
        <h1>Beauty Guru Recommendation System</h1>
        <span>TDI Capstone Proposal | Author: Nurvirta</span>
      </div>
    </div>
    <div class="row">
      <div class="col-sm-6 col-sm-offset-3">
      <h2>Background</h2>
      <p>In this 21st century, we rely so much on YouTube to know the latest trends and tutorials on how to do bunch of things. As women, most of us trust beauty guru on YouTube to get reviews on many cosmetics and how they look like when it is put on (color, quality, etc). However, sometimes when we try them on our face, the lipstick color, blush color, foundation shade are not what we were expecting because we watched the "wrong" youtuber: they have either lighter or darker skin tone than us. Therefore, I want to create an app to recommend the perfect beauty youtuber for each skin tone.</p>
      <h2>How the app works</h2>
      <p>
        <ol>
          <li>User uploads the photo of their face, or input the brand of foundation that they usually use.</li>
          <li>The pic will go through the system to get the recommendation (possibly neural networks)</li>
          <li>The output will be the list of their matching beauty youtubers, that have the most similar skin tone to theirs.</li>
        </ol>
        <div class="col-sm-12">
          <img src="{{ url_for('static', filename='img/mockup.JPG') }}">
        </div>
      </p>
      <h2>Methodology</h2>
      <h3>0. Data Collection</h3>
      <p>We gather the youtube video data from https://research.google.com/youtube8m/download.html, under label "cosmetics". There are around ~57,000 images there.</p>
      <h3>1. Labelling</h3>
      <p>There is no data with the ground truth for this case, such as person A has a fair-slightly-medium skintone). Therefore, we have to build our own training set. Here are some plans</p>
      <ul>
        <li>Run Clustering to get some clusters for classification classes</li>
        <li>Match the picture with foundation shade mentioned in the description box, if any</li>
        <li>Manual labelling based on MAC foundation shade</li>
        <div class="col-sm-12">
          <img src="{{ url_for('static', filename='img/mac.jpg') }}">
        </div>
      </ul>
      <h3>2. Train the data</h3>
      <p>After we figure out how to label the pictures properly, the next step is to train the data. There are two methods that are going to be applied</p>
      <ul>
        <li>K-nearest neighbor</li>
        <li>Deep Learning (possibly PyTorch or TensorFlow)</li>
      </ul>
      <h3>3. Testing and retrain</h3>
      <p>We are going to fine-tune and compare each models to get the best model</p>
      <h3>4. Build the app</h3>
      <p>We plan to build the app using using flask and or django.</p>

      <h2>First Iteration: Initial Exploration</h2>
      <p>The aims for this initial exploration are</p>
      <ol>
        <li>to explore the data,</li>
        <li>to test whether clustering is a feasible way to label the data</li>
      </ol>

      <p>I gathered all thumbnail videos from <a href="https://research.google.com/youtube8m/">Youtube 8M dataset</a> under cosmetics tag.
        Then crop the pictures square and centered, where most likely we can get the face.</p>
        <img src="{{ url_for('static', filename='img/face.png') }}">
       <p>I used KMeans clustering with k=3 to get the "dominant colors" for each image. Hopefully, we can get an idea of the distribution of the skintone.</p>
       <div class="col-sm-12">
         <img src="{{ url_for('static', filename='img/dominant_colors.png') }}">
        </div>
       <p>The second column (second most dark/light) is most likely where the skintone at. As we can see here, because the nature of skintone, we can not really "divide" the colors into some categories.</p>
       <p>The elbow plot below also explain that other than two clusters, there are not many classes we can gather from the clustering</p>
       <img src="{{ url_for('static', filename='img/elbow.png') }}">

        <p> Therefore, we are planning to manually set the class for skintone and hand-labeled some images as training data.</p>

       <p>Also, here is little exploration about how beauty youtuber write their video descriptions</p>
       <div class="col-sm-12">
       <img src="{{ url_for('static', filename='img/wordcloud.png') }}">
      </div>
       <p>As we can see here, lots of url shortener. Beauty youtuber tend to mention the products they use in the video and put the affiliate link.
         As the videos that explicitely mentions "foundation shade" are not that much, we are going to use this anchor to scrap the foundation shade and match them with the picture, so that we can get additional attribute.</p>

      <h2>Second Iteration: KNN with manually labelled data</h2>
      <p>As the clustering would not be a good fit to determine the classes for classification, we manually labelled the pictures into 5 classes with our own judgement.</p>
      <ol>
        <li>
          <p>Class 1: Fair</p>
          <img src="{{ url_for('static', filename='img/1.jpg') }}">
        </li>
        <li>
          <p>Class 2: Fair-Medium</p>
          <img src="{{ url_for('static', filename='img/2.jpg') }}"></li>
        <li>
          <p>Class 3: Medium</p>
          <img src="{{ url_for('static', filename='img/3.jpg') }}">
        </li>
        <li>
          <p>Class 4: Medium-Dark</p>
          <img src="{{ url_for('static', filename='img/4.jpg') }}">
        </li>
        <li>
          <p>Class 5: Dark</p>
          <img src="{{ url_for('static', filename='img/5.jpg') }}">
        </li>
      </ol>
      <p>We collected 2000 pictures, 1000 for training (200 each class), 1000 for testing (also 200 each class). </p>
      <p>We then applied KNN with k=1 with the color histogram as its features (512-d feature vector). We got 27.17% accuracy with 19.5% precision, which is not that good and looks rather arbitrary. Thus, the next step will be to scrap foundation shade on description box to get more valid result.</p>
    </div>
    </div>

  </div>
</body>
</html>
